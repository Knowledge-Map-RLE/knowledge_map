Отлично — у вас два требования, которые сильно влияют на выбор:

* граф **динамический** — частые вставки/удаления вершин и рёбер (онлайн-обновления), и
* вы хотите использовать **Sugiyama**-тип укладки, но **без этапа минимизации пересечений** (т.е. только layering + (опционально) простая упорядоченность внутри слоёв + координаты и dummy-nodes для длинных рёбер).

Это упрощает задачу: мы можем сосредоточиться на быстрых инкрементальных процедурах для **топологического порядка**, **назначения слоёв (levels)**, **поддержки dummy-nodes** и **инкрементального перерасчёта координат**. Ниже — подробное руководство: какие структуры данных использовать, какие алгоритмы применять, псевдо/реализация на Python (работающая и понятная), оценка сложности, варианты оптимизации и практические рекомендации для production.

---

## Ключевая идея (инкрементальный подход)

При динамичных изменениях **не нужно** пересчитывать всё заново. Поддерживайте в памяти для каждой вершины:

* `succ[]` — список исходящих соседей (out-adj)
* `pred[]` — список входящих соседей (in-adj)
* `layer[v]` — текущий слой (целое >= 0)
* `topo_index[v]` — позиция в текущем топологическом упорядочении (опционально, для быстрой проверки нарушения порядка)
* `out_degree` / `in_degree` (опционально)
* метаданные: закреплённые/запиненные слои (pinned)

При вставке/удалении рёбер корректируем только те вершины, чьи `layer` (или `topo_index`) стали некорректны — и распространяем изменения BFS-подобно по затронутой области. Это даёт сложность пропорциональную размеру **affected subgraph**, а не всему графу.

---

## Какие структуры данных лучше для частых изменений

### 1) В оперативной памяти (лучше всего)

* **Adjacency lists** реализованные как `vector<int>` (C++), `ArrayList` (Java) или `list/set` (Python) — быстрые вставки/удаления (амортизированно).
* **Двойной указатель**: храните и `out_adj` (для прохода вниз) и `in_adj` (для прохода вверх). Нужны оба для эффективного распространения изменений.
* Для больших графов храните эти списки как **дешёвые массивы/вектора** (не объекты), чтобы уменьшить overhead (C++/Rust или NetworKit/igraph).
* Для многопоточной среды используйте **sharding** (разбиение вершин по партициям) + локальные блокировки, либо actor-модель.

### 2) Для persistence / durability

* Для частых изменений не используйте CSR как основной live-структуры — CSR плохо обновляется.
* Подход: **Adjacency lists in memory** + **write-ahead log (WAL)** (Kafka/append-only), и **periodic rebuild** CSR/snapshot для аналитики.

### 3) Индексация и быстрый доступ по id

* Вертикально храните массивы/векторы свойств (layer, pred pointer offset и т.д.) — O(1) доступ по id.
* Если id не компактны, держите mapping `id -> compact_index`.

---

## Алгоритмика: что именно поддерживать инкрементально

### A) Поддержание корректной топологической сортировки (онлайн)

* Для DAG важно поддерживать топологический порядок. При добавлении ребра `u->v` нужно проверить, не создаёт ли оно цикл. (Если может — отклонять или обрабатывать отдельно).
* **Если цикл не создаётся**: возможно нарушен порядок (если `topo_index[u] >= topo_index[v]`), тогда нужно корректировать порядок на подмножестве вершин. Есть специальные онлайн-алгоритмы топологической сортировки (Pearce–Kelly, Bender et al.). Но простая практическая стратегия:

  * если `topo_index[u] < topo_index[v]` — порядок не нарушен, ничего не делаем (быстрая ветка).
  * иначе — выполните локальную корректировку: найдите минимальный подграф между `v` и `u` (reachable from `v` until encountering nodes with topo\_index > topo\_index\[u]) и реранжируйте — это обычно небольшая область при «обычных» данных.

Для многих практических сценариев **хватит** не поддерживать `topo_index` строго онлайн, а вместо этого поддерживать **layer** через longest-path и использовать quick check `layer[v] >= layer[u]+1` — для flow-укладки это достаточное условие (см. ниже).

### B) Назначение слоёв (layering) — incremental longest-path

Для Sugiyama чаще используют «longest-path layering» (rank = longest distance from sources) или вариант `median`/`network simplex` — но longest-path отлично подходит и проще в поддержке:

* **Изначально**: сделайте линейный проход в топологическом порядке:

  ```
  for v in topo:
      layer[v] = max( layer[pred] + 1 for pred in preds(v) )  (0 если нет предков)
  ```

  O(V+E).

* **Инкрементально (вставка ребра u->v)**:

  1. Если `layer[v] >= layer[u] + 1` — ничего не нужно делать (увязка слоёв соблюдена).
  2. Иначе — задаём `layer[v] = layer[u] + 1` и **пропагируем** увеличение: для каждого w in succ(v): если `layer[w] <= layer[v]` то `layer[w] = layer[v] + 1` и push w в очередь; и т.д. (BFS / queue).
  3. Эта процедура завершится, обновив только затронутый подграф. Сложность — O(size of affected subgraph).

* **Инкрементально (удаление ребра u->v)**:

  * Удаление может позволить **уменьшить** `layer` некоторых вершин. Уменьшение требует перерасчёта `layer` как `max(pred_layers)+1`. Можно:

    1. Для v проверяем новый `new_layer_v = max(pred_layers of v) + 1` (без u). Если `new_layer_v < layer[v]`, присваиваем и пушим v в очередь; для каждого successor w возможное уменьшение: recompute `max(pred_layers of w)+1` и т.д.
    2. В худшем это распространяется по большой части графа, но на практике часто локально.
  * Для уменьшений рекомендуется поддерживать структуру, где для каждой вершины хранится и число предков, или heap с предельными слоями — но чаще пересчёт `max(preds)` в локальной области достаточно.

> Замечание: увеличения легче, чем уменьшения, потому что увеличение можно делать монотонно; уменьшение требует смотреть всех предков.

### C) Dummy-nodes (long edges)

* В Sugiyama рёбра, которые пересекают >1 уровней, заменяются списком dummy-nodes, по одному на каждый промежуточный слой. В динамике:

  * храните для каждого исходного ребра `e=(u->v)` структуру: `if layer[v] == layer[u]+1 then edge is short else create/maintain dummy nodes between layers`.
  * при изменении `layer` ребра нужно **обновить** соответствующие dummy nodes: если spans increased, добавьте dummy nodes; если spans decreased to 1, удалите dummy nodes и замените возвращаемым реальным ребром.
  * dummy nodes — это просто вершины с флагом `is_dummy` и unique owner-edge id; они не участвуют в обычных операциях цитирования, и их `layer` фиксирован и меняется вместе с original endpoints (при массовых изменениях может потребоваться обновить mapping).

### D) Ordering внутри слоёв (без crossing minimization)

Вы сказали: **без** этапа уменьшения пересечений. Тогда порядок внутри слоя можно поддерживать просто и быстро:

* Вариант A (очень быстрый): сохранять **topological order** restricted to nodes of layer L (i.e. preserve original topo order). Это O(1) вставление — вставляем новый node at position based on topo index.
* Вариант B (слегка лучше): при вставке node `v` в layer `L` вычисляйте barycenter по родителям: `bary[v] = avg(order(parent))` и вставляйте с сортировкой по bary. Только один pass. Это O(deg(v) + log|L|).
* Вариант C (простая heuristic): сортировать по in-degree/out-degree/score (pagerank) — O(|L| log|L|) только на локальном уровне.

Поскольку вы отказались от итеративных crossing-minimization passes, все эти варианты дают быстрые изменения и достаточно читаемую визуализацию.

### E) Координаты (x,y)

* y = `layer * layer_spacing` — прямолинейно.
* x: внутри слоя — равномерно по order\_in\_layer (или использовать barycenter values scaled). Обновление x обычно локальное: при изменении порядка пересчитывайте x только для узлов в изменённом слое (or in a window).

---

## Псевдо-реализация (Python): инкрементальные операции

Ниже — рабочий, понятный, инкрементальный код (Python). Этот код написан для понятности; в продакшене переносите в C++/Rust или используйте JIT/numba, и храните списки в компактных массивах.

```python
from collections import deque, defaultdict

class DynamicSugiyama:
    def __init__(self):
        # adjacency as dict of sets for fast add/remove
        self.succ = defaultdict(set)
        self.pred = defaultdict(set)
        self.layer = dict()         # node -> layer (int)
        self.order_in_layer = defaultdict(list)  # layer -> list(nodes)  (keeps order)
        self.is_dummy = set()       # set of dummy node ids
        self.edge_to_dummies = {}   # (u,v) -> [d1,d2,...] mapping

    def add_node_if_missing(self, v):
        if v not in self.layer:
            self.layer[v] = 0
            self.order_in_layer[0].append(v)

    def insert_edge(self, u, v):
        """Insert directed edge u->v. Handle layers incrementally."""
        self.add_node_if_missing(u)
        self.add_node_if_missing(v)
        if v in self.succ[u]: 
            return  # already
        # add adjacency
        self.succ[u].add(v)
        self.pred[v].add(u)
        # check layer condition
        desired = self.layer[u] + 1
        if self.layer[v] >= desired:
            # nothing to do regarding layers
            pass
        else:
            # raise layer[v] and propagate
            self._increase_layer_bulk(v, desired)

        # update dummy nodes for this edge
        self._ensure_dummy_nodes_for_edge(u, v)

    def remove_edge(self, u, v):
        if v not in self.succ.get(u,()):
            return
        self.succ[u].remove(v)
        self.pred[v].remove(u)
        # remove any dummy nodes owned by this edge
        self._remove_dummy_nodes_for_edge(u,v)
        # check if some nodes can lower their layers
        # recompute layer[v] as max(pred_layers)+1
        new_layer = 0
        if self.pred[v]:
            new_layer = max(self.layer[p] for p in self.pred[v]) + 1
        if new_layer < self.layer[v]:
            self._decrease_layer_bulk(v, new_layer)

    def _increase_layer_bulk(self, start_node, new_layer):
        """BFS-style propagation for increasing layers."""
        q = deque()
        self._set_layer(start_node, new_layer)
        q.append(start_node)
        while q:
            u = q.popleft()
            for w in self.succ[u]:
                desired = self.layer[u] + 1
                if self.layer[w] < desired:
                    self._set_layer(w, desired)
                    q.append(w)

    def _decrease_layer_bulk(self, start_node, new_layer):
        """Propagate decreases: for each node recompute required layer from preds."""
        q = deque()
        self._set_layer(start_node, new_layer)
        q.append(start_node)
        while q:
            u = q.popleft()
            for w in self.succ[u]:
                required = 0
                if self.pred[w]:
                    required = max(self.layer[p] for p in self.pred[w]) + 1
                if required < self.layer[w]:
                    self._set_layer(w, required)
                    q.append(w)

    def _set_layer(self, node, layer_value):
        old = self.layer.get(node, 0)
        if old == layer_value:
            return
        # remove from old order list
        if old in self.order_in_layer:
            try:
                self.order_in_layer[old].remove(node)
            except ValueError:
                pass
        # set new
        self.layer[node] = layer_value
        # add to end of new layer (cheap policy)
        self.order_in_layer[layer_value].append(node)
        # update dummy nodes attached to incident edges
        # (recreate as necessary)
        for p in self.pred[node]:
            self._ensure_dummy_nodes_for_edge(p, node)
        for s in self.succ[node]:
            self._ensure_dummy_nodes_for_edge(node, s)

    def _ensure_dummy_nodes_for_edge(self, u, v):
        """Ensure dummy nodes exist for edge u->v if it spans layers."""
        # remove existing dummies for edge if any
        key = (u,v)
        if key in self.edge_to_dummies:
            # recompute if span changed
            prev = self.edge_to_dummies[key]
            need = max(0, self.layer[v] - self.layer[u] - 1)
            if len(prev) == need:
                return
            else:
                # remove previous dummy nodes
                for d in prev:
                    self.is_dummy.discard(d)
                    # also remove adjacencies if you stored them
                del self.edge_to_dummies[key]

        span = self.layer[v] - self.layer[u] - 1
        if span <= 0:
            return
        # create 'span' dummy nodes
        dummies = []
        last = u
        for i in range(span):
            d_id = f"__d__{u}_{v}_{i}"
            dummies.append(d_id)
            self.is_dummy.add(d_id)
            self.add_node_if_missing(d_id)
            # set dummy at layer u+1+i
            self._set_layer(d_id, self.layer[u] + 1 + i)
            # link last -> d_id
            self.succ[last].add(d_id)
            self.pred[d_id].add(last)
            last = d_id
        # final link last -> v
        self.succ[last].add(v)
        self.pred[v].add(last)
        self.edge_to_dummies[key] = dummies

    def _remove_dummy_nodes_for_edge(self, u, v):
        key = (u,v)
        if key not in self.edge_to_dummies: return
        for d in self.edge_to_dummies[key]:
            # remove dummy node (and links)
            for p in list(self.pred[d]):
                self.succ[p].discard(d)
            for s in list(self.succ[d]):
                self.pred[s].discard(d)
            self.succ.pop(d, None)
            self.pred.pop(d, None)
            self.is_dummy.discard(d)
            # remove from order lists
            layer = self.layer.pop(d, None)
            if layer is not None and d in self.order_in_layer[layer]:
                self.order_in_layer[layer].remove(d)
        del self.edge_to_dummies[key]

    def compute_coordinates(self, spacing_x=100, spacing_y=100):
        """Compute x,y for all nodes (cheap: uniform spacing by order_in_layer)."""
        coords = {}
        for layer, nodes in self.order_in_layer.items():
            for i, v in enumerate(nodes):
                coords[v] = (i * spacing_x, layer * spacing_y)
        return coords
```

**Пояснения по коду:**

* `insert_edge` и `remove_edge` — основные операции. Они обновляют слои локально.
* `_increase_layer_bulk` и `_decrease_layer_bulk` — BFS-пропагаторы изменений слоёв.
* dummy-nodes создаются динамично в `_ensure_dummy_nodes_for_edge`. В реальном коде лучше хранить dummy-nodes как компактные целые id, а не строки.
* `compute_coordinates` — очень простая схема координат: внутри слоя по порядку с постоянным шагом. Это быстро и детерминировано.

---

## Сложность и практическая оценка

* **Вставка ребра**: если `layer[v] >= layer[u]+1`, O(1). В противном случае — O(size of affected subgraph) (пропагирование increases). В типичных графах с локальной структуре «affected» невелик.
* **Удаление ребра**: может быть дорого (меньшение слоёв), опять же O(size of affected subgraph) в худшем.
* **Создание/удаление вершины**: аналогично комбинации insert/remove edges.
* **Dummy nodes**: создание — O(span) per edge (span = number of intermediate layers).
* **Память**: adjacency lists (out+in) — O(V + E). Dummy nodes увеличивают V & E but proportional to number of long edges and layer spans.

---

## Оптимизации / инженерные приёмы

1. **Batching**: если поток обновлений очень быстр (тысячи/миллионы в секунду), не применяйте каждый update синхронно к layout. Собирайте дельту, применяйте пакетно каждые X секунд / по событию, обновляя только нужную локальную область. Это сильно уменьшит накладные расходы.

2. **Sharding / partitioning**: разделите граф по ID (range/hashed) и обрабатывайте updates локально; пересечения между shard'ами требуют координации, но это масштабирует.

3. **Locking / concurrency**: используйте per-node или per-shard locks при update; избегайте глобальных блокировок.

4. **Lazy dummy management**: не создавайте dummy nodes сразу; для визуализации можно при отдаче клиенту динамически expand long edges into intermediate rendering segments (особенно если вы отдаёте tiles). Создание dummy nodes можно отложить на момент экспорта view.

5. **Use compact/native runtime**: Python справится на прототипе, но для реального сценария переносите код в C++/Rust/Go, или используйте NetworKit/igraph/graph-tool для больших объёмов.

6. **Indexing and quick reject checks**: храните `max_pred_layer[v]` (max layer among preds) для O(1) проверки при удалениях/вставках. Это позволит быстрее recompute `new_layer`.

7. **Metrics to avoid catastrophic propagation**: заранее ограничивайте max layer or add thresholds to avoid extremely deep propagation every update (меры защиты).

---

## Как это всё интегрировать с визуализацией (Pixi, tiles, LOD)

* **На сервере** храните final `layer` и `order_in_layer` (и, при желании, `x,y`) и публикуйте tiles/L0..Ln: для каждого view запрашивайте нужный слой/подграф.
* **Delta pushes**: при изменениях публикуйте только дельту (nodes moved, edges added/removed) клиентам через websocket; клиенты применяют к локальной визуализации.
* **Для больших графов** делайте LOD: render aggregated nodes / cluster representatives / heatmaps при большом zoom-out. Инкрементальная схема легко работает с LOD, потому что вы обновляете только base-level coordinates и затем агрегируете.

---

## Практические рекомендации (итоги)

1. **Используйте adjacency lists with in/out neighbors** (mutable) как базовую live-структуру. Не CSR для live updates.
2. **Поддерживайте layer\[]** и поддерживайте инкрементальную функцию `insert_edge` / `remove_edge`, как в примере. Для большинства реальных потоков это работает очень быстро — затрагиваются лишь локальные компоненты.
3. **Не делайте crossing minimization** — это и требование, и плюс: вы избегаете тяжёлых итерационных операций. Для чтимости применяйте одно-проходное правило порядка (topo-based или barycenter single-pass).
4. **Если частота обновлений большая** — batch updates, применяйте периодические snapshots (rebuild full layout) и real-time incremental updates для low-latency.
5. **Реализуйте на C++/Rust** при росте графа/нагрузки: Python лишь для прототипа.
6. **Мониторьте affected subgraph size** — если update часто вызывает затрагивание огромной доли графа, это сигнал, что ваша схема слоёв/архитектура данных не подходит (возможно, граф слишком плотный), и нужен другой подход (partitioning, rate-limiting).

---

Если хотите, могу:

* 1. подготовить **оптимизированную C++/pseudo-C** версию ключевых функций (`insert_edge`, `remove_edge`, `_increase_layer_bulk`) для портирования;
* 2. переписать приведённый Python-класс так, чтобы он использовал **compact integer ids**, `array('I')` или `numpy` для списков (меньше overhead) — и прислать код, который уже будет гораздо быстрее;
* 3. показать, как добавить **pinning** (фиксированные слои для некоторых узлов), и как это влияет на propagation;
* 4. сделать пример с **batched updates** (приёма deltas и применения раз в N секунд), с кодом и примером нагрузки.

Что из этого нужно вам в первую очередь?
