services:
  # Neo4j — база данных для хранения графовых данных
  neo4j:
    image: neo4j:5.13.0
    container_name: knowledge_map_neo4j
    ports:
      - "7474:7474"   # HTTP для Neo4j Browser
      - "7687:7687"   # Bolt
    environment:
      NEO4J_AUTH: neo4j/password
      NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
      NEO4J_server_memory_heap_initial__size: "2G"
      NEO4J_server_memory_heap_max__size: "3G"
      NEO4J_server_memory_pagecache_size: "3G"
      NEO4J_server_bolt_advertised__address: ":7687"
      NEO4J_db_transaction_timeout: "60m"
      NEO4J_server_jvm_additional: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC"
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_dbms_security_procedures_unrestricted: "apoc.*,gds.*"
      NEO4J_dbms_security_procedures_allowlist: "apoc.*,gds.*"
    ulimits:
      nofile:
        soft: 40000
        hard: 40000
    volumes:
      - C:/Data_Knowledge_Map/neo4j_data:/data
      - C:/Data_Knowledge_Map/neo4j_logs:/logs
      - C:/Data_Knowledge_Map/neo4j_import:/var/lib/neo4j/import
      - C:/Data_Knowledge_Map/neo4j_plugins:/plugins
    networks:
      - knowledge_map_network
    deploy:
      resources:
        limits:
          memory: 6G
    healthcheck:
      test: cypher-shell --username neo4j --password password 'MATCH () RETURN count(*) as count'
      interval: 15s
      timeout: 15s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  redis:
    image: redis/redis-stack:latest
    container_name: knowledge_map_redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    networks:
      - knowledge_map_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 10s

  auth:
    build:
      context: ./auth
      dockerfile: Dockerfile
    container_name: knowledge_map_auth
    restart: unless-stopped
    ports:
      - "50052:50051"  # gRPC порт для auth сервиса
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - REDIS_URL=redis://redis:6379
      - GRPC_HOST=0.0.0.0
      - GRPC_PORT=50051
      - SECRET_KEY=your-secret-key-change-in-production
      - ALGORITHM=HS256
      - ACCESS_TOKEN_EXPIRE_MINUTES=30
      - PASSWORD_MIN_LENGTH=8
      - RECOVERY_KEYS_COUNT=10
      - RECOVERY_KEY_LENGTH=16
      - LOGIN_ATTEMPTS_LIMIT=5
      - LOGIN_ATTEMPTS_WINDOW=300
    networks:
      - knowledge_map_network
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - auth_proto:/shared/proto
      - ./auth:/app
      - /app/__pycache__
      - /app/src/__pycache__
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  layout:
    build:
      context: ./layering
      dockerfile: Dockerfile
    container_name: knowledge_map_layout
    restart: unless-stopped
    ports:
      - "50053:50051"  # gRPC порт для layout сервиса
    environment:
      - LOG_LEVEL=INFO
    networks:
      - knowledge_map_network
    depends_on:
      neo4j:
        condition: service_healthy

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: knowledge_map_api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - LAYOUT_SERVICE_HOST=layout
      - LAYOUT_SERVICE_PORT=50051
      - AUTH_SERVICE_HOST=auth
      - AUTH_SERVICE_PORT=50051
      - DEBUG=true
    networks:
      - knowledge_map_network
    depends_on:
      neo4j:
        condition: service_healthy
      layout:
        condition: service_started
      auth:
        condition: service_started
    volumes:
      - auth_proto:/shared/proto
      - ./api:/app
      - /app/__pycache__
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    container_name: knowledge_map_client
    restart: unless-stopped
    ports:
      - "3000:80"
    networks:
      - knowledge_map_network
    depends_on:
      api:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  s3:
    image: minio/minio:RELEASE.2024-01-01T16-36-33Z
    container_name: knowledge_map_s3
    restart: unless-stopped
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123456
      MINIO_CONSOLE_ADDRESS: ":9001"
    command: server /data --console-address ":9001"
    volumes:
      -  C:/Data_Knowledge_Map/s3_data:/data
    networks:
      - knowledge_map_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 10s

  # === РАСПРЕДЕЛЁННАЯ УКЛАДКА ГРАФОВ ===
  
  # Основной воркер-менеджер для укладки графов
  layout_worker_manager:
    build:
      context: ./worker_distributed_layering
      dockerfile: Dockerfile
    container_name: knowledge_map_layout_manager
    restart: unless-stopped
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - REDIS_URL=redis://redis:6379/3
      - CELERY_BROKER_URL=redis://redis:6379/4
      - CELERY_RESULT_BACKEND=redis://redis:6379/5
      - CHUNK_SIZE=8000  # Увеличено с 5000 до 8000 для 4GB
      - MAX_WORKERS=4    # Увеличено с 2 до 4 для 4GB
      - MEMORY_LIMIT_GB=4.0  # Остаётся 4.0
      - ENABLE_NUMBA_JIT=true
      - ENABLE_CYTHON_OPTIMIZATION=true
      - LOG_LEVEL=INFO
      - PROMETHEUS_PORT=9100
    ports:
      - "9100:9100"
    volumes:
      - ./worker_distributed_layering/cypher_procedures:/app/cypher_procedures:ro
    networks:
      - knowledge_map_network
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: ["python", "main.py", "standalone"]
    healthcheck:
      test: ["CMD", "python", "main.py", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G      # ← Остаётся 4G
          cpus: '4.0'     # ← Увеличено с 2.0 до 4.0
        reservations:
          memory: 3G      # ← Увеличено с 2G до 3G
          cpus: '2.0'     # ← Увеличено с 1.0 до 2.0

  # Celery воркер для обработки графов
  layout_worker_1:
    build:
      context: ./worker_distributed_layering
      dockerfile: Dockerfile
    container_name: knowledge_map_layout_worker_1
    restart: unless-stopped
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - REDIS_URL=redis://redis:6379/3
      - CELERY_BROKER_URL=redis://redis:6379/4
      - CELERY_RESULT_BACKEND=redis://redis:6379/5
      - CHUNK_SIZE=6000  # Увеличено с 3000 до 6000
      - MEMORY_LIMIT_GB=4.0  # Увеличено с 3.0 до 4.0
      - ENABLE_NUMBA_JIT=true
      - LOG_LEVEL=INFO
      - WORKER_ID=1
    networks:
      - knowledge_map_network
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
      layout_worker_manager:
        condition: service_started
    command: ["celery", "-A", "src.tasks", "worker", "--loglevel=info", "--concurrency=2", "--queues=graph_processing"]
    deploy:
      resources:
        limits:
          memory: 4G      # ← Увеличено с 3G до 4G
          cpus: '2.0'     # ← Увеличено с 1.5 до 2.0
        reservations:
          memory: 2G      # ← Увеличено с 1G до 2G
          cpus: '1.0'     # ← Увеличено с 0.5 до 1.0

  # Воркер для оптимизации (опциональный - запускается при больших графах)
  layout_optimization_worker:
    build:
      context: ./worker_distributed_layering
      dockerfile: Dockerfile
    container_name: knowledge_map_layout_optimizer
    restart: unless-stopped
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - REDIS_URL=redis://redis:6379/3
      - CELERY_BROKER_URL=redis://redis:6379/4
      - CELERY_RESULT_BACKEND=redis://redis:6379/5
      - MEMORY_LIMIT_GB=3.0
      - ENABLE_NUMBA_JIT=true
      - ENABLE_CYTHON_OPTIMIZATION=true
      - LOG_LEVEL=INFO
      - WORKER_ID=optimization
    networks:
      - knowledge_map_network
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
      layout_worker_manager:
        condition: service_started
    command: ["celery", "-A", "src.tasks", "worker", "--loglevel=info", "--concurrency=1", "--queues=optimization"]
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    profiles:
      - production  # Запускается только при профиле production

  # Воркер для сохранения результатов
  layout_persistence_worker:
    build:
      context: ./worker_distributed_layering
      dockerfile: Dockerfile
    container_name: knowledge_map_layout_persistence
    restart: unless-stopped
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - REDIS_URL=redis://redis:6379/3
      - CELERY_BROKER_URL=redis://redis:6379/4
      - CELERY_RESULT_BACKEND=redis://redis:6379/5
      - MEMORY_LIMIT_GB=1.0
      - LOG_LEVEL=INFO
      - WORKER_ID=persistence
    networks:
      - knowledge_map_network
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
      layout_worker_manager:
        condition: service_started
    command: ["celery", "-A", "src.tasks", "worker", "--loglevel=info", "--concurrency=1", "--queues=persistence"]
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # Flower для мониторинга Celery (опциональный)
  layout_flower:
    build:
      context: ./worker_distributed_layering
      dockerfile: Dockerfile
    container_name: knowledge_map_layout_flower
    restart: unless-stopped
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/4
      - CELERY_RESULT_BACKEND=redis://redis:6379/5
    ports:
      - "5555:5555"
    networks:
      - knowledge_map_network
    depends_on:
      redis:
        condition: service_healthy
    command: ["celery", "-A", "src.tasks", "flower", "--port=5555"]
    profiles:
      - monitoring  # Запускается только с профилем monitoring

volumes:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  s3_data:
  auth_proto:
  nebula_storage0:
    driver: local

networks:
  knowledge_map_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16