# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: ai_model.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'ai_model.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0e\x61i_model.proto\x12\x08\x61i_model\"\xaf\x02\n\x13GenerateTextRequest\x12\x10\n\x08model_id\x18\x01 \x01(\t\x12\x0e\n\x06prompt\x18\x02 \x01(\t\x12\x17\n\nmax_tokens\x18\x03 \x01(\x05H\x00\x88\x01\x01\x12\x18\n\x0btemperature\x18\x04 \x01(\x02H\x01\x88\x01\x01\x12\x12\n\x05top_p\x18\x05 \x01(\x02H\x02\x88\x01\x01\x12\x12\n\x05top_k\x18\x06 \x01(\x05H\x03\x88\x01\x01\x12\x1f\n\x12repetition_penalty\x18\x07 \x01(\x02H\x04\x88\x01\x01\x12\x1c\n\x0f\x65nable_chunking\x18\x08 \x01(\x08H\x05\x88\x01\x01\x42\r\n\x0b_max_tokensB\x0e\n\x0c_temperatureB\x08\n\x06_top_pB\x08\n\x06_top_kB\x15\n\x13_repetition_penaltyB\x12\n\x10_enable_chunking\"\xb6\x01\n\x14GenerateTextResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x16\n\x0egenerated_text\x18\x02 \x01(\t\x12\x0f\n\x07message\x18\x03 \x01(\t\x12\x12\n\nmodel_used\x18\x04 \x01(\t\x12\x14\n\x0cinput_tokens\x18\x05 \x01(\x05\x12\x15\n\routput_tokens\x18\x06 \x01(\x05\x12\x0f\n\x07\x63hunked\x18\x07 \x01(\x08\x12\x12\n\nnum_chunks\x18\x08 \x01(\x05\"2\n\x10GetModelsRequest\x12\x13\n\x06\x66ilter\x18\x01 \x01(\tH\x00\x88\x01\x01\x42\t\n\x07_filter\"Z\n\x11GetModelsResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x0f\n\x07message\x18\x02 \x01(\t\x12#\n\x06models\x18\x03 \x03(\x0b\x32\x13.ai_model.ModelInfo\"\x7f\n\tModelInfo\x12\x10\n\x08model_id\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t\x12\x11\n\tis_loaded\x18\x04 \x01(\x08\x12\x1a\n\x12max_context_length\x18\x05 \x01(\x05\x12\x0e\n\x06\x64\x65vice\x18\x06 \x01(\t\"6\n\x12HealthCheckRequest\x12\x14\n\x07service\x18\x01 \x01(\tH\x00\x88\x01\x01\x42\n\n\x08_service\"Z\n\x13HealthCheckResponse\x12\x0e\n\x06status\x18\x01 \x01(\t\x12\x0f\n\x07service\x18\x02 \x01(\t\x12\x0f\n\x07\x64\x65tails\x18\x03 \x01(\t\x12\x11\n\ttimestamp\x18\x04 \x01(\t2\xf1\x01\n\x0e\x41IModelService\x12M\n\x0cGenerateText\x12\x1d.ai_model.GenerateTextRequest\x1a\x1e.ai_model.GenerateTextResponse\x12\x44\n\tGetModels\x12\x1a.ai_model.GetModelsRequest\x1a\x1b.ai_model.GetModelsResponse\x12J\n\x0bHealthCheck\x12\x1c.ai_model.HealthCheckRequest\x1a\x1d.ai_model.HealthCheckResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'ai_model_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_GENERATETEXTREQUEST']._serialized_start=29
  _globals['_GENERATETEXTREQUEST']._serialized_end=332
  _globals['_GENERATETEXTRESPONSE']._serialized_start=335
  _globals['_GENERATETEXTRESPONSE']._serialized_end=517
  _globals['_GETMODELSREQUEST']._serialized_start=519
  _globals['_GETMODELSREQUEST']._serialized_end=569
  _globals['_GETMODELSRESPONSE']._serialized_start=571
  _globals['_GETMODELSRESPONSE']._serialized_end=661
  _globals['_MODELINFO']._serialized_start=663
  _globals['_MODELINFO']._serialized_end=790
  _globals['_HEALTHCHECKREQUEST']._serialized_start=792
  _globals['_HEALTHCHECKREQUEST']._serialized_end=846
  _globals['_HEALTHCHECKRESPONSE']._serialized_start=848
  _globals['_HEALTHCHECKRESPONSE']._serialized_end=938
  _globals['_AIMODELSERVICE']._serialized_start=941
  _globals['_AIMODELSERVICE']._serialized_end=1182
# @@protoc_insertion_point(module_scope)
