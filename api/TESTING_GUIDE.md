# Knowledge Map API - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é

–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.

## üìã –ß—Ç–æ –±—ã–ª–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ

### 1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ—Å—Ç–æ–≤ –∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

```
api/
‚îú‚îÄ‚îÄ pytest.ini                           # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pytest
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                      # –û–±—â–∏–µ —Ñ–∏–∫—Å—Ç—É—Ä—ã
‚îÇ   ‚îú‚îÄ‚îÄ README.md                        # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ç–µ—Å—Ç–∞–º
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–∫—Å—Ç—É—Ä—ã
‚îÇ   ‚îú‚îÄ‚îÄ datasets/                        # –†–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md                    # –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema.json                  # JSON Schema –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_001/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ document.md          # Markdown —Ç–µ–∫—Å—Ç
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ document.pdf         # –ò—Å—Ö–æ–¥–Ω—ã–π PDF (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ metadata.json        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ annotations/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_001/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ linguistic.json      # –õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ relations.json       # –°–≤—è–∑–∏
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ chains.json          # –¶–µ–ø–æ—á–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ expected/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ sample_001/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ nlp_analysis.json    # –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ test_routers/                    # –¢–µ—Å—Ç—ã —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_nlp.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_action_chains.py
‚îÇ   ‚îú‚îÄ‚îÄ test_services/                   # –¢–µ—Å—Ç—ã —Å–µ—Ä–≤–∏—Å–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ test_integration/                # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
‚îÇ
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ dataset_builder/                 # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
        ‚îú‚îÄ‚îÄ export_dataset.py            # –≠–∫—Å–ø–æ—Ä—Ç –∏–∑ Neo4j
        ‚îú‚îÄ‚îÄ import_dataset.py            # –ò–º–ø–æ—Ä—Ç –≤ Neo4j
        ‚îî‚îÄ‚îÄ validate_dataset.py          # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
```

### 2. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏

#### üîÑ Export Dataset
–≠–∫—Å–ø–æ—Ä—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Neo4j –∏ S3 –≤ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞:

```bash
poetry run python tools/dataset_builder/export_dataset.py \
  --doc-id <doc_id> \
  --output sample_001 \
  --include-pdf
```

**–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç:**
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ Neo4j
- Markdown –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ S3
- PDF —Ñ–∞–π–ª –∏–∑ S3 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- –í—Å–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
- –°–≤—è–∑–∏ –º–µ–∂–¥—É –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
- –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏ —Ü–µ–ø–æ—á–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π

#### üì• Import Dataset
–ò–º–ø–æ—Ä—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ Neo4j –∏ S3 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

```bash
poetry run python tools/dataset_builder/import_dataset.py \
  --sample sample_001 \
  --clean
```

**–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç:**
- –°–æ–∑–¥–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ Neo4j
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç markdown –≤ S3
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç PDF –≤ S3 (–µ—Å–ª–∏ –µ—Å—Ç—å)
- –°–æ–∑–¥–∞–µ—Ç –≤—Å–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
- –°–æ–∑–¥–∞–µ—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
- –°–æ–∑–¥–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)

#### ‚úÖ Validate Dataset
–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞:

```bash
# –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
poetry run python tools/dataset_builder/validate_dataset.py --sample sample_001

# –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
poetry run python tools/dataset_builder/validate_dataset.py --all
```

**–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:**
- –°—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
- –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å JSON
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å offsets –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
- –°—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ referenced UIDs
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
- –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å–≤—è–∑–µ–π

### 3. Pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

#### pytest.ini
–ú–∞—Ä–∫–µ—Ä—ã –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤:
- `unit` - –ë—ã—Å—Ç—Ä—ã–µ unit —Ç–µ—Å—Ç—ã
- `integration` - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
- `nlp` - NLP-related —Ç–µ—Å—Ç—ã
- `dataset` - –¢–µ—Å—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
- `slow` - –ú–µ–¥–ª–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
- `requires_neo4j` - –¢—Ä–µ–±—É—é—Ç Neo4j
- `requires_s3` - –¢—Ä–µ–±—É—é—Ç S3

#### –§–∏–∫—Å—Ç—É—Ä—ã (conftest.py)

**–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:**
- `dataset_loader(sample_id, resource_path)` - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫
- `load_document_dataset(sample_id)` - –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ü–µ–ª–∏–∫–æ–º
- `load_annotations_dataset(sample_id)` - –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
- `load_expected_results(sample_id)` - –ó–∞–≥—Ä—É–∑–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

**Mock —Ñ–∏–∫—Å—Ç—É—Ä—ã:**
- `mock_s3_client` - –ú–æ–∫ S3 –∫–ª–∏–µ–Ω—Ç–∞
- `mock_neo4j_connection` - –ú–æ–∫ Neo4j —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è

**–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:**
- `sample_markdown_text` - –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
- `sample_annotations` - –ü—Ä–∏–º–µ—Ä –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
- `sample_relations` - –ü—Ä–∏–º–µ—Ä —Å–≤—è–∑–µ–π

**–£—Ç–∏–ª–∏—Ç—ã:**
- `assert_annotations_equal()` - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
- `assert_chains_equal()` - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–ø–æ—á–µ–∫

### 4. –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Å—Ç–æ–≤

#### test_nlp.py
- –¢–µ—Å—Ç—ã NLP –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
- –¢–µ—Å—Ç—ã –∞–≤—Ç–æ–∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
- –¢–µ—Å—Ç—ã multi-level –∞–Ω–∞–ª–∏–∑–∞ —Å –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ–º
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å ground truth

#### test_action_chains.py
- –¢–µ—Å—Ç—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ü–µ–ø–æ—á–µ–∫ –¥–µ–π—Å—Ç–≤–∏–π
- –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ó–∞–ø—É—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ—Å—Ç–æ–≤

```bash
cd api

# –í—Å–µ —Ç–µ—Å—Ç—ã
poetry run pytest tests/

# –¢–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã–µ unit —Ç–µ—Å—Ç—ã
poetry run pytest tests/ -m "unit and not slow"

# –¢–µ—Å—Ç—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
poetry run pytest tests/ -m dataset

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª
poetry run pytest tests/test_routers/test_nlp.py -v
```

### 2. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

**–í–∞—Ä–∏–∞–Ω—Ç A: –≠–∫—Å–ø–æ—Ä—Ç –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö**

1. –†–∞–∑–º–µ—Ç—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç–∫—Å–ø–æ—Ä—Ç:
   ```bash
   poetry run python tools/dataset_builder/export_dataset.py \
     --doc-id <your_doc_id> \
     --output sample_002 \
     --include-pdf
   ```
3. –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ:
   ```bash
   poetry run python tools/dataset_builder/validate_dataset.py --sample sample_002
   ```

**–í–∞—Ä–∏–∞–Ω—Ç B: –†—É—á–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ**

1. –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
   ```bash
   mkdir -p tests/datasets/documents/sample_002
   mkdir -p tests/datasets/annotations/sample_002
   mkdir -p tests/datasets/expected/sample_002
   ```

2. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª—ã —Å–æ–≥–ª–∞—Å–Ω–æ —Ñ–æ—Ä–º–∞—Ç—É (—Å–º. `tests/datasets/README.md`)

3. –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ:
   ```bash
   poetry run python tools/dataset_builder/validate_dataset.py --sample sample_002
   ```

### 3. –ù–∞–ø–∏—Å–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º

```python
import pytest

@pytest.mark.dataset
@pytest.mark.nlp
async def test_my_nlp_feature(load_document_dataset, load_expected_results):
    """Test NLP feature with dataset"""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    doc_data = load_document_dataset("sample_001")
    expected = load_expected_results("sample_001")

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
    from services.nlp_service import NLPService
    nlp_service = NLPService()
    result = nlp_service.analyze_text(doc_data["markdown"])

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    assert len(result["sentences"]) > 0
    assert "tokens" in result
```

## üìä Workflow —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

### –ü–µ—Ä–µ–¥ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–π —Ñ–∏—á–∏

1. –°–æ–∑–¥–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
2. –ù–∞–ø–∏—à–∏—Ç–µ —Ç–µ—Å—Ç—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞
3. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ–∏—á—É
4. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

### –ü–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º

```bash
# 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
poetry run python tools/dataset_builder/validate_dataset.py --all

# 2. –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä—ã—Ö —Ç–µ—Å—Ç–æ–≤
poetry run pytest tests/ -m "not slow" --tb=short

# 3. –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
poetry run pytest tests/ -v
```

### Continuous Integration (–±—É–¥—É—â–µ–µ)

–î–æ–±–∞–≤–∏—Ç—å –≤ GitHub Actions:
```yaml
- name: Validate datasets
  run: poetry run python tools/dataset_builder/validate_dataset.py --all

- name: Run tests
  run: poetry run pytest tests/ -v --cov=services --cov=src
```

## üìÅ –§–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

### –ü—Ä–∏–º–µ—Ä: linguistic.json

```json
{
  "annotations": [
    {
      "uid": "ann_001",
      "text": "–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º",
      "annotation_type": "VERB",
      "start_offset": 52,
      "end_offset": 63,
      "confidence": 0.95,
      "color": "#3B82F6",
      "metadata": {
        "pos": "VERB",
        "lemma": "–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å",
        "sent_idx": 0,
        "token_idx": 1
      },
      "source": "spacy",
      "processor_version": "3.7.0"
    }
  ]
}
```

### –ü—Ä–∏–º–µ—Ä: chains.json

```json
{
  "chains": [
    {
      "verbs": ["—Ä–∞–∑–º–µ—Ç–∏—Ç—å", "—Å–æ–±—Ä–∞—Ç—å", "–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å"],
      "sequence_type": "temporal",
      "confidence": 0.85,
      "evidence": ["–∑–∞—Ç–µ–º", "–¥–ª—è"]
    }
  ]
}
```

–ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å–º. –≤ [`tests/datasets/README.md`](tests/datasets/README.md)

## üéØ Best Practices

1. **–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:**
   - Small (~100-200 —Å–ª–æ–≤) –¥–ª—è unit —Ç–µ—Å—Ç–æ–≤
   - Medium (~500-1000 —Å–ª–æ–≤) –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
   - Large (~2000+ —Å–ª–æ–≤) –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤

2. **–ò–º–µ–Ω–æ–≤–∞–Ω–∏–µ:**
   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞: `sample_scientific_article_001`
   - –ù—É–º–µ—Ä—É–π—Ç–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ: `001`, `002`, `003`

3. **–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ:**
   - –ù–µ –∏–∑–º–µ–Ω—è–π—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –±–µ–∑ –∫—Ä–∞–π–Ω–µ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
   - –°–æ–∑–¥–∞–≤–∞–π—Ç–µ –Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏ –ø—Ä–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö

4. **–í–∞–ª–∏–¥–∞—Ü–∏—è:**
   - –í—Å–µ–≥–¥–∞ –≤–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º
   - –ó–∞–ø—É—Å–∫–∞–π—Ç–µ —Ç–µ—Å—Ç—ã –ª–æ–∫–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥ push

5. **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:**
   - –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
   - –£–∫–∞–∑—ã–≤–∞–π—Ç–µ –∫–∞–∫–∏–µ —Ç–µ—Å—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫–∞–∫–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã

## üîß Troubleshooting

### Dataset not found
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ
ls tests/datasets/documents/sample_001/
```

### Invalid JSON
```bash
# –í–∞–ª–∏–¥–∞—Ü–∏—è JSON
python -m json.tool tests/datasets/annotations/sample_001/linguistic.json
```

### Offset errors
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é
poetry run python tools/dataset_builder/validate_dataset.py --sample sample_001
```

### Import fails
```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --clean –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
poetry run python tools/dataset_builder/import_dataset.py --sample sample_001 --clean
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Datasets README](tests/datasets/README.md) - –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º
- [Tests README](tests/README.md) - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ç–µ—Å—Ç–∞–º
- [JSON Schema](tests/datasets/schema.json) - –°—Ö–µ–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

## üéâ –†–µ–∑—É–ª—å—Ç–∞—Ç

–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å:

‚úÖ –ü–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
‚úÖ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞/–∏–º–ø–æ—Ä—Ç–∞/–≤–∞–ª–∏–¥–∞—Ü–∏–∏
‚úÖ Pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏ –∏ —Ñ–∏–∫—Å—Ç—É—Ä–∞–º–∏
‚úÖ –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Å—Ç–æ–≤ –¥–ª—è NLP –∏ action chains
‚úÖ –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚úÖ –ü—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ (sample_001)

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**

1. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –≤–∞—à–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –¥–∞—Ç–∞—Å–µ—Ç—ã
2. –ù–∞–ø–∏—à–∏—Ç–µ —Ç–µ—Å—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –¥–µ–ø–ª–æ–µ–º
4. –î–æ–±–∞–≤—å—Ç–µ –≤ CI/CD pipeline
