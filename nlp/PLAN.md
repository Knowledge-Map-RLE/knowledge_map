# План реализации

- Стек: Python, Poetry, gRPC, Neo4j, Neomodel, Docker, S3, 
- Стек. Возможные Python-пакеты: spaCy, nltk, gensim, natasha, deeppavlov, pymorphy, UDPipe, pymystem3, PyDictionary, transformer, tensorflow, keras, BioBERT
- Место среди микросервисов: neo4j <-> nlp <-> api <-> client.
- Будет использоваться для работы с текстом на клиенте, где будет проверятся и использоваться человеком найденные лингвистические паттерны и правильно ли это сделано.

- Цель: средствами NLP из текста вытащена графовая лингвистическая структура и соответственно представлены сущности, действия и паттерны содержащиеся в нём, а также автоматическая разметка.
- На вход подан канонический для Карты Знаний текст в формате Markdown.

- Для каждого этапа должны быть протестированы модели, сделано сравнение между ними, выбрана лучшая для данной задачи, а остальные могут дополнять лучшую. Это должно быть сделано в виде Jupyter Notebook.
. Этапы есть такие:
  - Сбор данных (data ingestion)
  - Валидация
  - Предобработка (text preprocessing)
    - Очистка (text cleaning)
  - Нормализация (text normalization)
  - Сегментация (text segmentation)
  - Лингвистический анализ (linguistic analysis)
    - Токенизация (tokenization)
    - Морфологический анализ (❓)
      - Определение частей речи (POS-теггинг, Part-of-Speech)
      - Лемматизация (❓)
      - Стеминг (как альтернатива)
    - Синтаксический анализ (syntax analysis)
      - Разбор зависимостей (dependency parsing)
      - Распознавание сущностей (Named Entity Recognition, NER)
  - Семантический анализ (semantic analysis)
    - Векторизация (vectorisation)
    - Тематическое моделирование (❓)
      - ❓ (Latent Dirichlet Allocation, LDA)
      - BERTopic (современный подход)
  - Специализированные задачи (task-specific processing)
    - Классификация (classificaton)
    - Анализ тональности
    - Извлечение информации
      - Извлечение ключевых фраз (RAKE, YAKE)
      - Relationship extraction
      - Event extraction
      - Fact extraction
  - Продвинутая обработка (advanced processing)
    - Кореференция (coreference resolution)
    - Анафора и эллипсис:
      - Разрешение местоимений
      - Восстановление пропущенных элементов
    - Прагматический анализ
      - Определение намерений (Intent Recognition)
      - Ирония и сарказм
      - Контекстуальные импликатуры
  - Качество и валидация (quality assurance, QA)
    - Метрики качества
    - A/B тестирование
      - Shadow mode тестирование
      - Канареечные релизы
      - Сравнение моделей в реальном времени
  - Оптимизация и масштабирование (optimization and scaling)
    - Производительность
    - Кеширование
  - Мониторинг и логирование (monitoring and logging)
    - Метрики в реальном времени
    - Трейсинг и профилирование
  - Развёртывание и API (deployment and API)

- Исправлены ошибки в тексте.
  - Исправлены грамматические ошибки.
  - Исправлены пунктуационные ошибки.
- Выявлены члены предложений.
- Выявлены части речи.
  - Выявлены глаголы.
  - Выявлены существительные.
  - Выявлены прилагательные.
  - Выявлены союзы.
  - Выявлены частицы.
- Выявлены сущности (NER).
- Сняты неоднозначности.

- Сделаны таблицы перестановок слов в одном предложении для семантического анализа.
- Выявлены слова значения которых не меняются при перестановке. (эти типы стали есть в прокатном цехе)
- Сделаны таблицы перестановок предложений в одном тексте для смыслового анализа.
- Выявлены семантические связи в предложениях.
- Выявлены смыслы в тексте

- Получен процент покрытия текста алгоритмами — все ли смыслы текста попали в граф.
- На выходе получен граф лингвистической структуры текста, из которого можно полностью восстановить исходный текст и его разметку и метаданные и он сохранён в базе данных Neo4j.

## Надсистемы в которых будеет использоваться этот микросервис

- В ядре Карты Знаний, основных алгоритмах
- На клиенте пользователь будет видеть всю разметку лингвистических структур, делать рецензирование (или это будет делать AI) или использовать для преобразования в участок графа общей карты знаний.

## Данные которые должны сохраняться в базе данных

- Ссылка на текст
- Вся метаинформация текста
  - Название текста
  - Ссылка на исходный Markdown
  - Ссылка на преобразованный в Markdown и обработанный текст в S3 хранилище
  - Краткое описание
  - Тип текста: научная статья, книга, веб страница
  - Список URL для скачивания
  - DOI
  - Список авторов
  - Лицензия
  - и так далее